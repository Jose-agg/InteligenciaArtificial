# Cargar los datos
geneLevel <- read.csv('D:\\Jose\\Documentos\\Clases\\Sistemas Inteligentes\\Practicas\\5 - Aprendizaje Automatico\\Entrega\\TCGA-PANCAN-HiSeq-801x20531\\data.csv',stringsAsFactors = F)
label <- read.csv('D:\\Jose\\Documentos\\Clases\\Sistemas Inteligentes\\Practicas\\5 - Aprendizaje Automatico\\Entrega\\TCGA-PANCAN-HiSeq-801x20531\\labels.csv',stringsAsFactors = F)
tcga <- merge(geneLevel, label, sort = F)
tcga$X <- NULL
library(caret)
# Establecer el conjunto de datos con los que se va a trabajar
set.seed(251317)
tcga.filtered <- tcga[,c(sample(ncol(tcga)-1,100),ncol(tcga))]
# Crear las particiones
particion <- createDataPartition(y = tcga.filtered$gene_1609, p=0.75, list=FALSE)
training <- tcga.filtered[ particion,]
testing <- tcga.filtered[ -particion,]
# Eliminar las columnas vacias de las particiones
training <- training[,apply(tcga.filtered,2,function(x){all(x!=0)})]
testing <- testing[,apply(tcga.filtered,2,function(x){all(x!=0)})]
# Establecer el esquema de evaluacion
ctrl <- trainControl(
method = "cv"
)
# //////////////////////// #
# //////////////////////// #
# Arboles de Decision, Knn #
# //////////////////////// #
# //////////////////////// #
# Entrenar para C4.5
set.seed(251317)
c4.5FitTraining <- train(
Class ~ .,
data = training,
method = "J48",
trControl = ctrl
)
# Todos los resultados
c4.5FitTraining$results[,1:4]
# Mejor resultado
c4.5FitTraining$results[rownames(c4.5FitTraining$bestTune),1:4]
# Esto se hace porque no coinciden los niveles de 'data' y 'reference'. Mas información en este enlace https://stackoverflow.com/questions/19871043/r-package-caret-confusionmatrix-with-missing-categories
# Comprobar resultados en testing para C4.5
u <- union(predict(c4.5FitTraining,testing), testing$Class)
t <- table(factor(predict(c4.5FitTraining,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Entrenar para RPart
set.seed(251317)
rpartFitTraining <- train(
Class ~ .,
data = training,
method = "rpart",
trControl = ctrl,
tuneLength = 15
)
# Todos los resultados
rpartFitTraining$results[,1:3]
# Mejor resultado
rpartFitTraining$results[rownames(rpartFitTraining$bestTune),1:3]
# Comprobar resultados en testing para rpart
u <- union(predict(rpartFitTraining,testing), testing$Class)
t <- table(factor(predict(rpartFitTraining,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Entrenar para RPart2
set.seed(251317)
rpart2FitTraining <- train(
Class ~ .,
data = training,
method = "rpart2",
trControl = ctrl,
tuneLength = 7
)
# Todos los resultados
rpart2FitTraining$results[,1:3]
# Mejor resultado
rpart2FitTraining$results[rownames(rpart2FitTraining$bestTune),1:3]
# Comprobar resultados en testing para rpart2
u <- union(predict(rpart2FitTraining,testing), testing$Class)
t <- table(factor(predict(rpart2FitTraining,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Entrenar para Knn
set.seed(251317)
knnFitTraining <- train(
Class ~ .,
data = training,
method = "knn",
trControl = ctrl,
tuneLength = 15
)
# Todos los resultados
knnFitTraining$results[,1:3]
# Mejor resultado
knnFitTraining$results[rownames(knnFitTraining$bestTune),1:3]
# Comprobar resultados en testing para knn
u <- union(predict(knnFitTraining,testing), testing$Class)
t <- table(factor(predict(knnFitTraining,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# //////////////////////// #
# //////////////////////// #
# Redes Neuronales #
# //////////////////////// #
# //////////////////////// #
# Entrenar una red neuronal de 1 capa
set.seed(251317)
redesNeuronales1Capa <- train(
Class ~ .,
data = training,
method = "mlpML",
trControl = ctrl,
tuneGrid = expand.grid(layer1=seq(11,21,2),layer2=0,layer3=0),
maxit = 1000,
learnFuncParams = c(0.03,0)
)
# Todos los resultados
redesNeuronales1Capa$results[,1:5]
# Mejor resultado
redesNeuronales1Capa$results[rownames(redesNeuronales1Capa$bestTune),1:5]
# Comprobar resultados en testing para 1 capa
u <- union(predict(redesNeuronales1Capa,testing), testing$Class)
t <- table(factor(predict(redesNeuronales1Capa,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Entrenar una red neuronal de 2 capas
set.seed(251317)
redesNeuronales2Capa <- train(
Class ~ .,
data = training,
method = "mlpML",
trControl = ctrl,
tuneGrid = expand.grid(layer1=seq(17,21,2),layer2=seq(17,21,2),layer3=0),
maxit = 1000,
learnFuncParams = c(0.03,0)
)
# Todos los resultados
redesNeuronales2Capa$results[,1:5]
# Mejor resultado
redesNeuronales2Capa$results[rownames(redesNeuronales2Capa$bestTune),1:5]
# Comprobar resultados en testing para 2 capa
u <- union(predict(redesNeuronales2Capa,testing), testing$Class)
t <- table(factor(predict(redesNeuronales2Capa,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Entrenar una red neuronal de 3 capas
set.seed(251317)
redesNeuronales3Capa <- train(
Class ~ .,
data = training,
method = "mlpML",
trControl = ctrl,
tuneGrid = expand.grid(layer1=seq(17,21,2),layer2=seq(17,21,2),layer3=seq(17,21,2)),
maxit = 1000,
learnFuncParams = c(0.03,0)
)
# Todos los resultados
redesNeuronales3Capa$results[,1:5]
# Mejor resultado
redesNeuronales3Capa$results[rownames(redesNeuronales3Capa$bestTune),1:5]
# Comprobar resultados en testing para 3 capa
u <- union(predict(redesNeuronales3Capa,testing), testing$Class)
t <- table(factor(predict(redesNeuronales3Capa,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Mostrar la comparativa de tiempos entre los entrenamientos de diferentes ccantidades de capas
dfm.complejidad.tiempo <- data.frame(tiempo = c(redesNeuronales1Capa$times$final[1],
redesNeuronales2Capa$times$final[1],
redesNeuronales3Capa$times$final[1]),
capas = factor(c('1','2','3')))
ggplot(dfm.complejidad.tiempo, aes(x=capas,y=tiempo,fill=capas)) + geom_col()
# //////////////////////// #
# //////////////////////// #
# Maquinas Vector Soporte  #
# //////////////////////// #
# //////////////////////// #
# //// Formato Lineal \\\\ #
# Entrenar con margen duro
set.seed(251317)
svmLinealDuro <- train(
Class ~ .,
data = training,
method = "svmLinear",
trControl = ctrl,
tuneGrid = data.frame(C=500),
scale = FALSE
)
# El resultado
svmLinealDuro$results[,1:3]
# Probando con los datos de testing
u <- union(predict(svmLinealDuro,testing), testing$Class)
t <- table(factor(predict(svmLinealDuro,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Entrenar con margen blando
set.seed(251317)
svmLinealBlando <- train(
Class ~ .,
data = training,
method = "svmLinear",
trControl = ctrl,
tuneGrid = data.frame(C=1),
scale = FALSE
)
# El resultado
svmLinealBlando$results[,1:3]
# Probando con los datos de testing
u <- union(predict(svmLinealBlando,testing), testing$Class)
t <- table(factor(predict(svmLinealBlando,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# //// Formato no Lineal \\\\ #
# Entrenamiento con kernel polinomial de grado 2, 3, 4 y 5
set.seed(251317)
svmPolinomial <- train(
Class ~ .,
data = training,
method = "svmPoly",
trControl = ctrl,
tuneGrid = expand.grid(degree=c(2,3,4,5),C=c(2,3,4,5),scale = c(0.1, 0.5, 1))
)
# Resultados
svmPolinomial$results[,1:5]
# Mejor Resultado
svmPolinomial$results[rownames(svmPolinomial$bestTune),1:5]
# Probando con los datos de testing
u <- union(predict(svmPolinomial,testing), testing$Class)
t <- table(factor(predict(svmPolinomial,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Entrenamiento con kernel radial con sigma 3, 5 y 7
set.seed(251317)
svmRadial <- train(
Class ~ .,
data = training,
method = "svmRadial",
trControl = ctrl,
tuneGrid = expand.grid(sigma=c(3,5,7),C=c(1,5,10))
)
# Resultados
svmRadial$results[,1:4]
# Mejor Resultado
svmRadial$results[rownames(svmRadial$bestTune),1:4]
# Probando con los datos de testing
u <- union(predict(svmRadial,testing), testing$Class)
t <- table(factor(predict(svmRadial,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# //////////////////////// #
# //////////////////////// #
#  Comparacion de Modelos  #
# //////////////////////// #
# //////////////////////// #
# //// Resultados \\\\ #
# C4.5
c4.5FitTraining$results[rownames(c4.5FitTraining$bestTune),1:4]
u <- union(predict(c4.5FitTraining,testing), testing$Class)
t <- table(factor(predict(c4.5FitTraining,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# RPart
rpartFitTraining$results[rownames(rpartFitTraining$bestTune),1:3]
u <- union(predict(rpartFitTraining,testing), testing$Class)
t <- table(factor(predict(rpartFitTraining,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# RPart2
rpart2FitTraining$results[rownames(rpart2FitTraining$bestTune),1:3]
u <- union(predict(rpart2FitTraining,testing), testing$Class)
t <- table(factor(predict(rpart2FitTraining,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Knn
knnFitTraining$results[rownames(knnFitTraining$bestTune),1:3]
u <- union(predict(knnFitTraining,testing), testing$Class)
t <- table(factor(predict(knnFitTraining,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Red neuronal 1 capa
redesNeuronales1Capa$results[rownames(redesNeuronales1Capa$bestTune),1:5]
u <- union(predict(redesNeuronales1Capa,testing), testing$Class)
t <- table(factor(predict(redesNeuronales1Capa,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Red neuronal 2 capas
redesNeuronales2Capa$results[rownames(redesNeuronales2Capa$bestTune),1:5]
u <- union(predict(redesNeuronales2Capa,testing), testing$Class)
t <- table(factor(predict(redesNeuronales2Capa,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Red neuronal 3 capas
redesNeuronales3Capa$results[rownames(redesNeuronales3Capa$bestTune),1:5]
u <- union(predict(redesNeuronales3Capa,testing), testing$Class)
t <- table(factor(predict(redesNeuronales3Capa,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Lineal Margen Duro
svmLinealDuro$results[,1:3]
u <- union(predict(svmLinealDuro,testing), testing$Class)
t <- table(factor(predict(svmLinealDuro,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Lineal Margen Blando
svmLinealBlando$results[,1:3]
u <- union(predict(svmLinealBlando,testing), testing$Class)
t <- table(factor(predict(svmLinealBlando,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Polinomial
svmPolinomial$results[rownames(svmPolinomial$bestTune),1:5]
u <- union(predict(svmPolinomial,testing), testing$Class)
t <- table(factor(predict(svmPolinomial,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Radial
svmRadial$results[rownames(svmRadial$bestTune),1:4]
u <- union(predict(svmRadial,testing), testing$Class)
t <- table(factor(predict(svmRadial,testing), u), factor(testing$Class, u))
confusionMatrix(t)$overall[1:4]
# Comparativa de tiempos entre los 4 mejores algoritmos. No se tiene en cuenta la red neuronal de 1 capa porque desvirtúa el resto de tiempos.
dfm.complejidad.tiempo <- data.frame(tiempo = c(knnFitTraining$times$final[1],
svmLinealDuro$times$final[1],
svmLinealBlando$times$final[1],
svmPolinomial$times$final[1]),
modelos = factor(c('Knn','Lineal_Duro','Lineal_Blando','Polinomial')))
ggplot(dfm.complejidad.tiempo, aes(x=modelos,y=tiempo,fill=modelos)) + geom_col()
# Knn es el que se ha decidio escoger como mejor, y ahora se ponen a comparar como de buenos son sus resultados frente a los de los demas
# Prueba Knn frente a C4.5
binom.test(round(c(0.9597167, 1-0.9597167)* nrow(testing)), p = 0.8090432)
t.test(knnFitTraining$resample$Kappa,c4.5FitTraining$resample$Kappa,paired = T)
# Prueba Knn frente a RPart
binom.test(round(c(0.9597167, 1-0.9597167)* nrow(testing)), p = 0.7992169)
t.test(knnFitTraining$resample$Kappa,rpartFitTraining$resample$Kappa,paired = T)
# Prueba Knn frente a RPart 2
binom.test(round(c(0.9597167, 1-0.9597167)* nrow(testing)), p = 0.8058317)
t.test(knnFitTraining$resample$Kappa,rpart2FitTraining$resample$Kappa,paired = T)
# Prueba Knn frente a Red Neuronal 1 capa
binom.test(round(c(0.9597167, 1-0.9597167)* nrow(testing)), p = 0.9730622)
t.test(knnFitTraining$resample$Kappa,redesNeuronales1Capa$resample$Kappa,paired = T)
# Prueba Knn frente a Red Neuronal 2 capas
binom.test(round(c(0.9597167, 1-0.9597167)* nrow(testing)), p = 0.8770954)
t.test(knnFitTraining$resample$Kappa,redesNeuronales2Capa$resample$Kappa,paired = T)
# Prueba Knn frente a Red Neuronal 3 capas
binom.test(round(c(0.9597167, 1-0.9597167)* nrow(testing)), p = 0.4542491)
t.test(knnFitTraining$resample$Kappa,redesNeuronales3Capa$resample$Kappa,paired = T)
# Prueba Knn frente a SVM lineal con margen duro
binom.test(round(c(0.9597167, 1-0.9597167)* nrow(testing)), p = 0.9731282)
t.test(knnFitTraining$resample$Kappa,svmLinealDuro$resample$Kappa,paired = T)
# Prueba Knn frente a SVM lineal con margen blando
binom.test(round(c(0.9597167, 1-0.9597167)* nrow(testing)), p = 0.9731282)
t.test(knnFitTraining$resample$Kappa,svmLinealBlando$resample$Kappa,paired = T)
# Prueba Knn frente a SVM polinomial
binom.test(round(c(0.9597167, 1-0.9597167)* nrow(testing)), p = 0.9730613)
t.test(knnFitTraining$resample$Kappa,svmPolinomial$resample$Kappa,paired = T)
# Prueba Knn frente a SVM radial
binom.test(round(c(0.9597167, 1-0.9597167)* nrow(testing)), p = 0.0000000)
t.test(knnFitTraining$resample$Kappa,svmRadial$resample$Kappa,paired = T)
savehistory("D:/Jose/Documentos/Clases/Sistemas Inteligentes/Practicas/5 - Aprendizaje Automatico/Entrega/ComandosEjecutados.Rhistory")
